{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore Warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    warnings.filterwarnings('ignore')\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_numeric_columns(df, exclude_cols):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_transformed = df.copy()\n",
    "    \n",
    "    # Select only numeric columns\n",
    "    num_cols = df_transformed.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Exclude specified columns\n",
    "    cols_to_transform = [col for col in num_cols if col not in exclude_cols]\n",
    "    \n",
    "    # Apply the PowerTransformer with the yeo-johnson method\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    df_transformed[cols_to_transform] = pt.fit_transform(df_transformed[cols_to_transform])\n",
    "    \n",
    "    return df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbgrp_performance(df, groupby_col, label_map):\n",
    "    \"\"\"\n",
    "    This function takes in a DataFrame, a column name and a label map and creates a confusion matrix for each unique value in the specified column.\n",
    "\n",
    "    :param df: DataFrame containing true labels, predicted labels and groupby column\n",
    "    :type df: pandas.DataFrame\n",
    "    :param groupby_col: Column name to group data by\n",
    "    :type groupby_col: str\n",
    "    :param label_map: Dictionary that maps integer labels to string labels\n",
    "    :type label_map: dict\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a list of unique values in the specified column\n",
    "    groups = df[groupby_col].unique()\n",
    "\n",
    "    # Sort the groups in ascending order\n",
    "    groups.sort()\n",
    "\n",
    "    # Create a figure with subplots for each group\n",
    "    fig, axs = plt.subplots(1, len(groups), figsize=(5 * len(groups), 5))\n",
    "\n",
    "    # Loop through each group\n",
    "    for i, group in enumerate(groups):\n",
    "        # Filter the DataFrame to only include data for the current group\n",
    "        df_group = df[df[groupby_col] == group]\n",
    "\n",
    "        # Get the true and predicted labels for the current group\n",
    "        y_true = df_group['Movement']\n",
    "        y_pred = df_group['prediction_label']\n",
    "\n",
    "        # Calculate the confusion matrix for the current group\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Convert the confusion matrix to a DataFrame with appropriate column and row labels\n",
    "        columns = [label_map[i] for i in range(len(label_map))]\n",
    "        df_cm = pd.DataFrame(cm, columns=columns, index=columns)\n",
    "\n",
    "        # Create a seaborn heatmap to visualize the confusion matrix on the corresponding subplot\n",
    "        ax = sns.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Greens', cbar=False, ax=axs[i]) # font size\n",
    "\n",
    "        # Calculate performance metrics for the current group\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        # Update the layout of the heatmap to include a title and axis labels\n",
    "        ax.set_title(f'Confusion Matrix for {groupby_col} {group}\\n Accuracy: {acc:.2f}, AUC: {auc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}')\n",
    "        ax.set_xlabel('Predicted Label')\n",
    "        ax.set_ylabel('True Label')\n",
    "\n",
    "    # Show the figure with all subplots\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../Data/FinalDF/FinalDF.csv\", encoding=\"utf-8\", sep=\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to exclude\n",
    "cols_to_exclude = ['Company', 'year', \"day\", \"month\", 'Is Trading Day', \"day_of_week\",\"day_of_year\",\"quarter\", 'cos_day','sin_day']\n",
    "\n",
    "# Transform the numeric features of the dataset\n",
    "df = transform_numeric_columns(df, cols_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the \"Date\" column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map companies and Movement an create inversions for future refference\n",
    "company_map={'AMAZON': 0, 'APPLE': 1, 'TESLA': 2, 'MICROSOFT':3}\n",
    "movement_map={\"Up\":1, \"Down\":0}\n",
    "\n",
    "inverted_company_map={v: k for k, v in company_map.items()}\n",
    "inverted_movement_map={v: k for k, v in movement_map.items()}\n",
    "\n",
    "df['Company']=df['Company'].map(company_map)\n",
    "\n",
    "df['Movement']=df['Movement'].map(movement_map)\n",
    "df['PWD Movement']=df['PWD Movement'].map(movement_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TimeSeriesSplit object with the desired number of splits\n",
    "val_size=0.3\n",
    "\n",
    "train_data, val_data = train_test_split(df, test_size=val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=\"Movement\"\n",
    "# Drop Close and Movement columns to avoid data leakage\n",
    "class_df_train=train_data.drop(columns=[\"Date\", 'Close', \"Adj Close\", \"Price Change\"])\n",
    "\n",
    "class_df_val=val_data.drop(columns=[\"Date\", 'Close', \"Adj Close\", \"Price Change\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Classification Experiment Enviroment\n",
    "setup=setup(class_df_train, target=target, session_id = 124, n_jobs=-1, fold=20, use_gpu=True, feature_selection=True, fix_imbalance=True,\n",
    "            keep_features=['Company', 'year', \"day\", \"month\", \"day_of_week\", \"day_of_year\",\"quarter\", 'cos_day','sin_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top model in terms of auc\n",
    "top_models = compare_models(n_select = 8, sort = 'acc', include=[\"knn\", \"mlp\", \"rf\", \"et\", \"lr\", \"lightgbm\", 'ridge','rbfsvm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models_table=pull()\n",
    "top_models_table.to_excel(\"../Predictions/top_models.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns = ['Model', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa', 'MCC'])\n",
    "\n",
    "\n",
    "for model in top_models:\n",
    "    predict_test = predict_model(model)\n",
    "    predict_test_df = pull()\n",
    "    test_df = pd.concat([test_df, predict_test_df], ignore_index=True, sort=False)\n",
    "test_df.to_excel(\"../Predictions/test_top_models.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune top 3 models\n",
    "#tuned_top3 = [tune_model(i, optimize = 'acc', early_stopping=True) for i in top_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Top Model\n",
    "#bagged_model=ensemble_model(top_models[0], method = 'Bagging', choose_better=True, optimize='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend top 3 models\n",
    "#blender = blend_models(top_models, choose_better=True, optimize='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model of the classification experiment\n",
    "#best_model=automl(optimize = 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with also the test data\n",
    "#final_model=finalize_model(best_model)\n",
    "\n",
    "list_of_models = []\n",
    "\n",
    "for model in top_models:\n",
    "    final_model = finalize_model(model)\n",
    "    list_of_models.append(final_model)\n",
    "# Copy the final Training Results\n",
    "trainning_results=pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final Training Results\n",
    "trainning_results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model parameters\n",
    "parameters=plot_model(final_model, plot='parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict on the validation set\n",
    "#predictions = predict_model(final_model, data=class_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(final_model)\n",
    "validation_df = pd.DataFrame(columns = ['Model', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa', 'MCC'])\n",
    "\n",
    "for model in list_of_models:\n",
    "    predictions = predict_model(model, data=class_df_val)\n",
    "    validaton_results = pull()\n",
    "    validation_df = pd.concat([validation_df, validaton_results], ignore_index=True, sort=False)\n",
    "    if model ==list_of_models[0]:\n",
    "        predictions2 = predictions\n",
    "    \n",
    "validation_df.to_excel(\"../Predictions/validation_top_models.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance\n",
    "plot_model(list_of_models[0], plot='feature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions2\n",
    "predictions = predictions[predictions['Is Trading Day'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Mapping for Movement and Company collumns for Confusion Matrices\n",
    "predictions['Company'] = predictions['Company'].map(inverted_company_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confussion Matrix for Unseen Data\n",
    "# Get the true and predicted labels for the current group\n",
    "y_true = predictions['Movement']\n",
    "y_pred = predictions['prediction_label']\n",
    "\n",
    "# Calculate the confusion matrix for the current group\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm)\n",
    "\n",
    "# Convert the confusion matrix to a DataFrame with appropriate column and row labels\n",
    "columns = [inverted_movement_map[i] for i in range(len(inverted_movement_map))]\n",
    "df_cm = pd.DataFrame(cm, columns=columns, index=columns)\n",
    "\n",
    "# Calculate performance metrics for the current group\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Create a seaborn heatmap to visualize the confusion matrix\n",
    "ax = sns.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Greens', cbar=False)\n",
    "\n",
    "# Update the layout of the heatmap to include a title and axis labels\n",
    "ax.set_title(f'Confusion matrix for unseen data\\n Accuracy: {acc:.2f}  AUC: {auc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confussion Matrix for Unseen Data\n",
    "# Get the true and predicted labels for the current group\n",
    "for company in predictions['Company'].unique():\n",
    "    predictions_per_company = predictions[predictions['Company']== company]\n",
    "    y_true = predictions_per_company['Movement']\n",
    "    y_pred = predictions_per_company['prediction_label']\n",
    "\n",
    "    # Calculate the confusion matrix for the current group\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "\n",
    "    # Convert the confusion matrix to a DataFrame with appropriate column and row labels\n",
    "    columns = [inverted_movement_map[i] for i in range(len(inverted_movement_map))]\n",
    "    df_cm = pd.DataFrame(cm, columns=columns, index=columns)\n",
    "\n",
    "    # Calculate performance metrics for the current group\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Create a seaborn heatmap to visualize the confusion matrix\n",
    "    ax = sns.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Greens', cbar=False)\n",
    "\n",
    "    # Update the layout of the heatmap to include a title and axis labels\n",
    "    ax.set_title(f'Confusion matrix for unseen data - {company} \\n Accuracy: {acc:.2f}  AUC: {auc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "\n",
    "    # Show the heatmap\n",
    "    print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confussion Matrix for Unseen Data\n",
    "# Get the true and predicted labels for the current group\n",
    "for year in predictions['year'].unique():\n",
    "    predictions_per_company = predictions[predictions['year']== year]\n",
    "    y_true = predictions_per_company['Movement']\n",
    "    y_pred = predictions_per_company['prediction_label']\n",
    "\n",
    "    # Calculate the confusion matrix for the current group\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "\n",
    "    # Convert the confusion matrix to a DataFrame with appropriate column and row labels\n",
    "    columns = [inverted_movement_map[i] for i in range(len(inverted_movement_map))]\n",
    "    df_cm = pd.DataFrame(cm, columns=columns, index=columns)\n",
    "\n",
    "    # Calculate performance metrics for the current group\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Create a seaborn heatmap to visualize the confusion matrix\n",
    "    ax = sns.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 12}, cmap='Greens', cbar=False)\n",
    "\n",
    "    # Update the layout of the heatmap to include a title and axis labels\n",
    "    ax.set_title(f'Confusion matrix for unseen data - {year} \\n Accuracy: {acc:.2f}  AUC: {auc:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "\n",
    "    # Show the heatmap\n",
    "    print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_excel(\"../Predictions/predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, cohen_kappa_score, matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Select actual and predicted classes\n",
    "y_true = predictions['Movement']\n",
    "y_pred = predictions['prediction_label']\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='micro')  # 'micro' calculates metrics globally\n",
    "precision = precision_score(y_true, y_pred, average='micro')  # 'micro' calculates metrics globally\n",
    "f1 = f1_score(y_true, y_pred, average='micro')  # 'micro' calculates metrics globally\n",
    "\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# In order to compute ROC AUC for multiclass, we need to binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_true)\n",
    "y_true_bin = lb.transform(y_true)\n",
    "y_pred_bin = lb.transform(y_pred)\n",
    "\n",
    "auc = roc_auc_score(y_true_bin, y_pred_bin, average='macro')\n",
    "auc_micro = roc_auc_score(y_true_bin, y_pred_bin, average='micro')\n",
    "auc_weighted = roc_auc_score(y_true_bin, y_pred_bin, average='weighted')\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "# Create DataFrame for the results\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"lgbm\"],  # Replace with your model name\n",
    "    \"Accuracy\": [accuracy],\n",
    "    \"AUC\": [auc],\n",
    "    \"AUC Micro\": [auc_micro],\n",
    "    \"AUC Weighted\": [auc_weighted],\n",
    "    \"Recall\": [recall],\n",
    "    \"Precision\": [precision],\n",
    "    \"F1\": [f1],\n",
    "    \"Kappa\": [kappa],\n",
    "    \"MCC\": [mcc],\n",
    "    \"Macro Precision\": [report['macro avg']['precision']],\n",
    "    \"Macro Recall\": [report['macro avg']['recall']],\n",
    "    \"Macro F1\": [report['macro avg']['f1-score']],\n",
    "    \"Weighted Recall\": [report['weighted avg']['recall']],\n",
    "    \"Weighted Precision\": [report['weighted avg']['precision']],\n",
    "    \"Weighted F1\": [report['weighted avg']['f1-score']],\n",
    "})\n",
    "\n",
    "results.to_excel(\"../Predictions/trading_days_validation_lgbm_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "class_distribution = y_true.value_counts(normalize=True)\n",
    "\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PycaretTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "398dc7ca74a063b6a3ad7962fe12ae9d7ec73f1688c081a686696be4cfa86e7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
